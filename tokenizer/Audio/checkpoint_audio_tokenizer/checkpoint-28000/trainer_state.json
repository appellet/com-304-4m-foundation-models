{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.929242773541407,
  "eval_steps": 500,
  "global_step": 28000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03546728143287817,
      "grad_norm": 0.002618912374600768,
      "learning_rate": 9.964881163533169e-05,
      "loss": 0.0043,
      "step": 100
    },
    {
      "epoch": 0.07093456286575633,
      "grad_norm": 0.014808031730353832,
      "learning_rate": 9.929407591344448e-05,
      "loss": 0.0041,
      "step": 200
    },
    {
      "epoch": 0.10640184429863452,
      "grad_norm": 0.05385678634047508,
      "learning_rate": 9.893934019155729e-05,
      "loss": 0.0039,
      "step": 300
    },
    {
      "epoch": 0.14186912573151267,
      "grad_norm": 0.011410940438508987,
      "learning_rate": 9.858460446967011e-05,
      "loss": 0.004,
      "step": 400
    },
    {
      "epoch": 0.17733640716439084,
      "grad_norm": 0.015779023990035057,
      "learning_rate": 9.822986874778291e-05,
      "loss": 0.0039,
      "step": 500
    },
    {
      "epoch": 0.17733640716439084,
      "eval_loss": 0.003943214192986488,
      "eval_runtime": 32.1278,
      "eval_samples_per_second": 37.973,
      "eval_steps_per_second": 9.493,
      "step": 500
    },
    {
      "epoch": 0.21280368859726903,
      "grad_norm": 0.008222403936088085,
      "learning_rate": 9.787513302589571e-05,
      "loss": 0.0038,
      "step": 600
    },
    {
      "epoch": 0.2482709700301472,
      "grad_norm": 0.009599175304174423,
      "learning_rate": 9.752039730400851e-05,
      "loss": 0.0038,
      "step": 700
    },
    {
      "epoch": 0.28373825146302534,
      "grad_norm": 0.006591546814888716,
      "learning_rate": 9.716566158212133e-05,
      "loss": 0.0037,
      "step": 800
    },
    {
      "epoch": 0.31920553289590353,
      "grad_norm": 0.004961076192557812,
      "learning_rate": 9.681092586023412e-05,
      "loss": 0.0036,
      "step": 900
    },
    {
      "epoch": 0.35467281432878167,
      "grad_norm": 0.0014128180919215083,
      "learning_rate": 9.645619013834693e-05,
      "loss": 0.0036,
      "step": 1000
    },
    {
      "epoch": 0.35467281432878167,
      "eval_loss": 0.0037836492992937565,
      "eval_runtime": 31.9177,
      "eval_samples_per_second": 38.223,
      "eval_steps_per_second": 9.556,
      "step": 1000
    },
    {
      "epoch": 0.39014009576165987,
      "grad_norm": 0.009498676285147667,
      "learning_rate": 9.610145441645975e-05,
      "loss": 0.0036,
      "step": 1100
    },
    {
      "epoch": 0.42560737719453806,
      "grad_norm": 0.009139702655375004,
      "learning_rate": 9.574671869457255e-05,
      "loss": 0.0034,
      "step": 1200
    },
    {
      "epoch": 0.4610746586274162,
      "grad_norm": 0.005424301140010357,
      "learning_rate": 9.539198297268535e-05,
      "loss": 0.0036,
      "step": 1300
    },
    {
      "epoch": 0.4965419400602944,
      "grad_norm": 0.002645739121362567,
      "learning_rate": 9.503724725079816e-05,
      "loss": 0.0036,
      "step": 1400
    },
    {
      "epoch": 0.5320092214931725,
      "grad_norm": 0.004750821739435196,
      "learning_rate": 9.468251152891097e-05,
      "loss": 0.0035,
      "step": 1500
    },
    {
      "epoch": 0.5320092214931725,
      "eval_loss": 0.0036792305763810873,
      "eval_runtime": 32.0669,
      "eval_samples_per_second": 38.045,
      "eval_steps_per_second": 9.511,
      "step": 1500
    },
    {
      "epoch": 0.5674765029260507,
      "grad_norm": 0.0042282831855118275,
      "learning_rate": 9.432777580702377e-05,
      "loss": 0.0034,
      "step": 1600
    },
    {
      "epoch": 0.6029437843589289,
      "grad_norm": 0.0073286863043904305,
      "learning_rate": 9.397304008513657e-05,
      "loss": 0.0035,
      "step": 1700
    },
    {
      "epoch": 0.6384110657918071,
      "grad_norm": 0.013185866177082062,
      "learning_rate": 9.361830436324939e-05,
      "loss": 0.0035,
      "step": 1800
    },
    {
      "epoch": 0.6738783472246852,
      "grad_norm": 0.002381762722507119,
      "learning_rate": 9.326356864136219e-05,
      "loss": 0.0036,
      "step": 1900
    },
    {
      "epoch": 0.7093456286575633,
      "grad_norm": 0.0023640841245651245,
      "learning_rate": 9.2908832919475e-05,
      "loss": 0.0035,
      "step": 2000
    },
    {
      "epoch": 0.7093456286575633,
      "eval_loss": 0.0036016234662383795,
      "eval_runtime": 32.0788,
      "eval_samples_per_second": 38.031,
      "eval_steps_per_second": 9.508,
      "step": 2000
    },
    {
      "epoch": 0.7448129100904416,
      "grad_norm": 0.004949595313519239,
      "learning_rate": 9.25540971975878e-05,
      "loss": 0.0034,
      "step": 2100
    },
    {
      "epoch": 0.7802801915233197,
      "grad_norm": 0.0019772271625697613,
      "learning_rate": 9.219936147570061e-05,
      "loss": 0.0034,
      "step": 2200
    },
    {
      "epoch": 0.8157474729561979,
      "grad_norm": 0.005419704131782055,
      "learning_rate": 9.184462575381341e-05,
      "loss": 0.0034,
      "step": 2300
    },
    {
      "epoch": 0.8512147543890761,
      "grad_norm": 0.0064939227886497974,
      "learning_rate": 9.148989003192622e-05,
      "loss": 0.0035,
      "step": 2400
    },
    {
      "epoch": 0.8866820358219543,
      "grad_norm": 0.009834219701588154,
      "learning_rate": 9.113515431003903e-05,
      "loss": 0.0036,
      "step": 2500
    },
    {
      "epoch": 0.8866820358219543,
      "eval_loss": 0.0035308944061398506,
      "eval_runtime": 32.2375,
      "eval_samples_per_second": 37.844,
      "eval_steps_per_second": 9.461,
      "step": 2500
    },
    {
      "epoch": 0.9221493172548324,
      "grad_norm": 0.004214161075651646,
      "learning_rate": 9.078041858815183e-05,
      "loss": 0.0035,
      "step": 2600
    },
    {
      "epoch": 0.9576165986877105,
      "grad_norm": 0.010934321209788322,
      "learning_rate": 9.042568286626464e-05,
      "loss": 0.0035,
      "step": 2700
    },
    {
      "epoch": 0.9930838801205888,
      "grad_norm": 0.0037816856056451797,
      "learning_rate": 9.007094714437744e-05,
      "loss": 0.0034,
      "step": 2800
    },
    {
      "epoch": 1.0283738251463026,
      "grad_norm": 0.0030239911284297705,
      "learning_rate": 8.971621142249025e-05,
      "loss": 0.0033,
      "step": 2900
    },
    {
      "epoch": 1.0638411065791806,
      "grad_norm": 0.004011018667370081,
      "learning_rate": 8.936147570060305e-05,
      "loss": 0.0034,
      "step": 3000
    },
    {
      "epoch": 1.0638411065791806,
      "eval_loss": 0.003480809973552823,
      "eval_runtime": 32.2757,
      "eval_samples_per_second": 37.799,
      "eval_steps_per_second": 9.45,
      "step": 3000
    },
    {
      "epoch": 1.0993083880120589,
      "grad_norm": 0.01074080727994442,
      "learning_rate": 8.900673997871586e-05,
      "loss": 0.0034,
      "step": 3100
    },
    {
      "epoch": 1.1347756694449371,
      "grad_norm": 0.009748092852532864,
      "learning_rate": 8.865200425682867e-05,
      "loss": 0.0033,
      "step": 3200
    },
    {
      "epoch": 1.1702429508778152,
      "grad_norm": 0.008455966599285603,
      "learning_rate": 8.829726853494147e-05,
      "loss": 0.0033,
      "step": 3300
    },
    {
      "epoch": 1.2057102323106934,
      "grad_norm": 0.006600873079150915,
      "learning_rate": 8.794253281305428e-05,
      "loss": 0.0034,
      "step": 3400
    },
    {
      "epoch": 1.2411775137435717,
      "grad_norm": 0.00854864064604044,
      "learning_rate": 8.758779709116709e-05,
      "loss": 0.0032,
      "step": 3500
    },
    {
      "epoch": 1.2411775137435717,
      "eval_loss": 0.0034454104024916887,
      "eval_runtime": 31.8679,
      "eval_samples_per_second": 38.283,
      "eval_steps_per_second": 9.571,
      "step": 3500
    },
    {
      "epoch": 1.2766447951764497,
      "grad_norm": 0.011284899897873402,
      "learning_rate": 8.72330613692799e-05,
      "loss": 0.0033,
      "step": 3600
    },
    {
      "epoch": 1.312112076609328,
      "grad_norm": 0.009902779944241047,
      "learning_rate": 8.68783256473927e-05,
      "loss": 0.0034,
      "step": 3700
    },
    {
      "epoch": 1.3475793580422062,
      "grad_norm": 0.011238847859203815,
      "learning_rate": 8.65235899255055e-05,
      "loss": 0.0034,
      "step": 3800
    },
    {
      "epoch": 1.3830466394750842,
      "grad_norm": 0.006196747533977032,
      "learning_rate": 8.616885420361831e-05,
      "loss": 0.0033,
      "step": 3900
    },
    {
      "epoch": 1.4185139209079625,
      "grad_norm": 0.004295472055673599,
      "learning_rate": 8.581411848173111e-05,
      "loss": 0.0033,
      "step": 4000
    },
    {
      "epoch": 1.4185139209079625,
      "eval_loss": 0.0034187098499387503,
      "eval_runtime": 32.1644,
      "eval_samples_per_second": 37.93,
      "eval_steps_per_second": 9.483,
      "step": 4000
    },
    {
      "epoch": 1.4539812023408405,
      "grad_norm": 0.003737403778359294,
      "learning_rate": 8.545938275984392e-05,
      "loss": 0.0033,
      "step": 4100
    },
    {
      "epoch": 1.4894484837737187,
      "grad_norm": 0.003524395637214184,
      "learning_rate": 8.510464703795673e-05,
      "loss": 0.0033,
      "step": 4200
    },
    {
      "epoch": 1.5249157652065968,
      "grad_norm": 0.0026260109152644873,
      "learning_rate": 8.474991131606953e-05,
      "loss": 0.0033,
      "step": 4300
    },
    {
      "epoch": 1.5603830466394752,
      "grad_norm": 0.0076536196283996105,
      "learning_rate": 8.439517559418234e-05,
      "loss": 0.0034,
      "step": 4400
    },
    {
      "epoch": 1.5958503280723533,
      "grad_norm": 0.017826788127422333,
      "learning_rate": 8.404043987229514e-05,
      "loss": 0.0032,
      "step": 4500
    },
    {
      "epoch": 1.5958503280723533,
      "eval_loss": 0.0033773749601095915,
      "eval_runtime": 32.4042,
      "eval_samples_per_second": 37.649,
      "eval_steps_per_second": 9.412,
      "step": 4500
    },
    {
      "epoch": 1.6313176095052313,
      "grad_norm": 0.0066514466889202595,
      "learning_rate": 8.368570415040795e-05,
      "loss": 0.0032,
      "step": 4600
    },
    {
      "epoch": 1.6667848909381096,
      "grad_norm": 0.002565526869148016,
      "learning_rate": 8.333096842852076e-05,
      "loss": 0.0032,
      "step": 4700
    },
    {
      "epoch": 1.7022521723709878,
      "grad_norm": 0.008393222466111183,
      "learning_rate": 8.297623270663356e-05,
      "loss": 0.0033,
      "step": 4800
    },
    {
      "epoch": 1.7377194538038658,
      "grad_norm": 0.004288932774215937,
      "learning_rate": 8.262149698474637e-05,
      "loss": 0.0033,
      "step": 4900
    },
    {
      "epoch": 1.773186735236744,
      "grad_norm": 0.0039113666862249374,
      "learning_rate": 8.226676126285918e-05,
      "loss": 0.0032,
      "step": 5000
    },
    {
      "epoch": 1.773186735236744,
      "eval_loss": 0.003344185184687376,
      "eval_runtime": 31.935,
      "eval_samples_per_second": 38.203,
      "eval_steps_per_second": 9.551,
      "step": 5000
    },
    {
      "epoch": 1.8086540166696223,
      "grad_norm": 0.004311274271458387,
      "learning_rate": 8.191202554097198e-05,
      "loss": 0.0032,
      "step": 5100
    },
    {
      "epoch": 1.8441212981025004,
      "grad_norm": 0.0051773227751255035,
      "learning_rate": 8.155728981908478e-05,
      "loss": 0.0032,
      "step": 5200
    },
    {
      "epoch": 1.8795885795353786,
      "grad_norm": 0.0033466611057519913,
      "learning_rate": 8.12025540971976e-05,
      "loss": 0.0033,
      "step": 5300
    },
    {
      "epoch": 1.9150558609682569,
      "grad_norm": 0.012155499309301376,
      "learning_rate": 8.08478183753104e-05,
      "loss": 0.0032,
      "step": 5400
    },
    {
      "epoch": 1.950523142401135,
      "grad_norm": 0.0029070384334772825,
      "learning_rate": 8.04930826534232e-05,
      "loss": 0.0031,
      "step": 5500
    },
    {
      "epoch": 1.950523142401135,
      "eval_loss": 0.003317677415907383,
      "eval_runtime": 32.2321,
      "eval_samples_per_second": 37.85,
      "eval_steps_per_second": 9.463,
      "step": 5500
    },
    {
      "epoch": 1.9859904238340131,
      "grad_norm": 0.006729393731802702,
      "learning_rate": 8.013834693153601e-05,
      "loss": 0.0032,
      "step": 5600
    },
    {
      "epoch": 2.0212803688597267,
      "grad_norm": 0.009081041440367699,
      "learning_rate": 7.978361120964882e-05,
      "loss": 0.0031,
      "step": 5700
    },
    {
      "epoch": 2.056747650292605,
      "grad_norm": 0.003667418612167239,
      "learning_rate": 7.942887548776162e-05,
      "loss": 0.0031,
      "step": 5800
    },
    {
      "epoch": 2.0922149317254832,
      "grad_norm": 0.005078908987343311,
      "learning_rate": 7.907413976587442e-05,
      "loss": 0.0032,
      "step": 5900
    },
    {
      "epoch": 2.1276822131583613,
      "grad_norm": 0.002913492498919368,
      "learning_rate": 7.871940404398724e-05,
      "loss": 0.0031,
      "step": 6000
    },
    {
      "epoch": 2.1276822131583613,
      "eval_loss": 0.00329960766248405,
      "eval_runtime": 32.3091,
      "eval_samples_per_second": 37.76,
      "eval_steps_per_second": 9.44,
      "step": 6000
    },
    {
      "epoch": 2.1631494945912397,
      "grad_norm": 0.01819927804172039,
      "learning_rate": 7.836466832210004e-05,
      "loss": 0.0031,
      "step": 6100
    },
    {
      "epoch": 2.1986167760241178,
      "grad_norm": 0.0035949992015957832,
      "learning_rate": 7.800993260021284e-05,
      "loss": 0.0032,
      "step": 6200
    },
    {
      "epoch": 2.234084057456996,
      "grad_norm": 0.008972474373877048,
      "learning_rate": 7.765519687832566e-05,
      "loss": 0.0031,
      "step": 6300
    },
    {
      "epoch": 2.2695513388898743,
      "grad_norm": 0.004026867914944887,
      "learning_rate": 7.730046115643846e-05,
      "loss": 0.0032,
      "step": 6400
    },
    {
      "epoch": 2.3050186203227523,
      "grad_norm": 0.004270301666110754,
      "learning_rate": 7.694572543455126e-05,
      "loss": 0.0031,
      "step": 6500
    },
    {
      "epoch": 2.3050186203227523,
      "eval_loss": 0.0032808503601700068,
      "eval_runtime": 32.2717,
      "eval_samples_per_second": 37.804,
      "eval_steps_per_second": 9.451,
      "step": 6500
    },
    {
      "epoch": 2.3404859017556303,
      "grad_norm": 0.00872319471091032,
      "learning_rate": 7.659453706988294e-05,
      "loss": 0.0032,
      "step": 6600
    },
    {
      "epoch": 2.375953183188509,
      "grad_norm": 0.004370764829218388,
      "learning_rate": 7.623980134799575e-05,
      "loss": 0.0032,
      "step": 6700
    },
    {
      "epoch": 2.411420464621387,
      "grad_norm": 0.004885239526629448,
      "learning_rate": 7.588506562610855e-05,
      "loss": 0.0031,
      "step": 6800
    },
    {
      "epoch": 2.446887746054265,
      "grad_norm": 0.020947299897670746,
      "learning_rate": 7.553032990422136e-05,
      "loss": 0.003,
      "step": 6900
    },
    {
      "epoch": 2.4823550274871433,
      "grad_norm": 0.006903911475092173,
      "learning_rate": 7.517559418233416e-05,
      "loss": 0.0032,
      "step": 7000
    },
    {
      "epoch": 2.4823550274871433,
      "eval_loss": 0.003261787351220846,
      "eval_runtime": 31.8574,
      "eval_samples_per_second": 38.296,
      "eval_steps_per_second": 9.574,
      "step": 7000
    },
    {
      "epoch": 2.5178223089200213,
      "grad_norm": 0.0025687902234494686,
      "learning_rate": 7.482085846044698e-05,
      "loss": 0.0031,
      "step": 7100
    },
    {
      "epoch": 2.5532895903528994,
      "grad_norm": 0.0031501136254519224,
      "learning_rate": 7.446612273855977e-05,
      "loss": 0.0031,
      "step": 7200
    },
    {
      "epoch": 2.588756871785778,
      "grad_norm": 0.0033211035188287497,
      "learning_rate": 7.411138701667258e-05,
      "loss": 0.0031,
      "step": 7300
    },
    {
      "epoch": 2.624224153218656,
      "grad_norm": 0.008482902310788631,
      "learning_rate": 7.375665129478539e-05,
      "loss": 0.0032,
      "step": 7400
    },
    {
      "epoch": 2.659691434651534,
      "grad_norm": 0.005596994888037443,
      "learning_rate": 7.340191557289819e-05,
      "loss": 0.0031,
      "step": 7500
    },
    {
      "epoch": 2.659691434651534,
      "eval_loss": 0.0032411455176770687,
      "eval_runtime": 32.2343,
      "eval_samples_per_second": 37.848,
      "eval_steps_per_second": 9.462,
      "step": 7500
    },
    {
      "epoch": 2.6951587160844124,
      "grad_norm": 0.005664977710694075,
      "learning_rate": 7.3047179851011e-05,
      "loss": 0.0032,
      "step": 7600
    },
    {
      "epoch": 2.7306259975172904,
      "grad_norm": 0.007795997429639101,
      "learning_rate": 7.26924441291238e-05,
      "loss": 0.0031,
      "step": 7700
    },
    {
      "epoch": 2.7660932789501684,
      "grad_norm": 0.0020945786964148283,
      "learning_rate": 7.233770840723662e-05,
      "loss": 0.0032,
      "step": 7800
    },
    {
      "epoch": 2.801560560383047,
      "grad_norm": 0.004192229826003313,
      "learning_rate": 7.198297268534941e-05,
      "loss": 0.003,
      "step": 7900
    },
    {
      "epoch": 2.837027841815925,
      "grad_norm": 0.002925546607002616,
      "learning_rate": 7.162823696346223e-05,
      "loss": 0.0031,
      "step": 8000
    },
    {
      "epoch": 2.837027841815925,
      "eval_loss": 0.0032287221401929855,
      "eval_runtime": 32.2436,
      "eval_samples_per_second": 37.837,
      "eval_steps_per_second": 9.459,
      "step": 8000
    },
    {
      "epoch": 2.872495123248803,
      "grad_norm": 0.00595857622101903,
      "learning_rate": 7.127350124157503e-05,
      "loss": 0.003,
      "step": 8100
    },
    {
      "epoch": 2.907962404681681,
      "grad_norm": 0.009404628537595272,
      "learning_rate": 7.091876551968783e-05,
      "loss": 0.0031,
      "step": 8200
    },
    {
      "epoch": 2.9434296861145595,
      "grad_norm": 0.007318093907088041,
      "learning_rate": 7.056402979780064e-05,
      "loss": 0.0032,
      "step": 8300
    },
    {
      "epoch": 2.9788969675474375,
      "grad_norm": 0.0032905000261962414,
      "learning_rate": 7.020929407591345e-05,
      "loss": 0.0032,
      "step": 8400
    },
    {
      "epoch": 3.0141869125731513,
      "grad_norm": 0.00486246170476079,
      "learning_rate": 6.985455835402626e-05,
      "loss": 0.0031,
      "step": 8500
    },
    {
      "epoch": 3.0141869125731513,
      "eval_loss": 0.0032180410344153643,
      "eval_runtime": 32.3208,
      "eval_samples_per_second": 37.747,
      "eval_steps_per_second": 9.437,
      "step": 8500
    },
    {
      "epoch": 3.0496541940060293,
      "grad_norm": 0.0041933185420930386,
      "learning_rate": 6.949982263213905e-05,
      "loss": 0.0031,
      "step": 8600
    },
    {
      "epoch": 3.085121475438908,
      "grad_norm": 0.010322390124201775,
      "learning_rate": 6.914863426747073e-05,
      "loss": 0.0032,
      "step": 8700
    },
    {
      "epoch": 3.120588756871786,
      "grad_norm": 0.0031182323582470417,
      "learning_rate": 6.879389854558355e-05,
      "loss": 0.0032,
      "step": 8800
    },
    {
      "epoch": 3.156056038304664,
      "grad_norm": 0.00535294134169817,
      "learning_rate": 6.843916282369635e-05,
      "loss": 0.003,
      "step": 8900
    },
    {
      "epoch": 3.1915233197375423,
      "grad_norm": 0.0026314337737858295,
      "learning_rate": 6.808442710180915e-05,
      "loss": 0.003,
      "step": 9000
    },
    {
      "epoch": 3.1915233197375423,
      "eval_loss": 0.0031964625231921673,
      "eval_runtime": 32.3883,
      "eval_samples_per_second": 37.668,
      "eval_steps_per_second": 9.417,
      "step": 9000
    },
    {
      "epoch": 3.2269906011704204,
      "grad_norm": 0.009999429807066917,
      "learning_rate": 6.772969137992197e-05,
      "loss": 0.003,
      "step": 9100
    },
    {
      "epoch": 3.2624578826032984,
      "grad_norm": 0.010061699897050858,
      "learning_rate": 6.737495565803477e-05,
      "loss": 0.003,
      "step": 9200
    },
    {
      "epoch": 3.297925164036177,
      "grad_norm": 0.011082700453698635,
      "learning_rate": 6.702021993614757e-05,
      "loss": 0.003,
      "step": 9300
    },
    {
      "epoch": 3.333392445469055,
      "grad_norm": 0.009683926589787006,
      "learning_rate": 6.666548421426038e-05,
      "loss": 0.0031,
      "step": 9400
    },
    {
      "epoch": 3.368859726901933,
      "grad_norm": 0.004618922248482704,
      "learning_rate": 6.631074849237319e-05,
      "loss": 0.0031,
      "step": 9500
    },
    {
      "epoch": 3.368859726901933,
      "eval_loss": 0.003185079200193286,
      "eval_runtime": 32.4361,
      "eval_samples_per_second": 37.612,
      "eval_steps_per_second": 9.403,
      "step": 9500
    },
    {
      "epoch": 3.404327008334811,
      "grad_norm": 0.004341416526585817,
      "learning_rate": 6.595601277048599e-05,
      "loss": 0.0031,
      "step": 9600
    },
    {
      "epoch": 3.4397942897676894,
      "grad_norm": 0.0020351361017674208,
      "learning_rate": 6.56012770485988e-05,
      "loss": 0.0031,
      "step": 9700
    },
    {
      "epoch": 3.4752615712005674,
      "grad_norm": 0.004515181295573711,
      "learning_rate": 6.524654132671161e-05,
      "loss": 0.0032,
      "step": 9800
    },
    {
      "epoch": 3.510728852633446,
      "grad_norm": 0.004629778675734997,
      "learning_rate": 6.489180560482441e-05,
      "loss": 0.0032,
      "step": 9900
    },
    {
      "epoch": 3.546196134066324,
      "grad_norm": 0.00684340437874198,
      "learning_rate": 6.454061724015608e-05,
      "loss": 0.003,
      "step": 10000
    },
    {
      "epoch": 3.546196134066324,
      "eval_loss": 0.00317765143699944,
      "eval_runtime": 32.0647,
      "eval_samples_per_second": 38.048,
      "eval_steps_per_second": 9.512,
      "step": 10000
    },
    {
      "epoch": 3.581663415499202,
      "grad_norm": 0.009353304281830788,
      "learning_rate": 6.41858815182689e-05,
      "loss": 0.003,
      "step": 10100
    },
    {
      "epoch": 3.61713069693208,
      "grad_norm": 0.009696004912257195,
      "learning_rate": 6.38311457963817e-05,
      "loss": 0.0031,
      "step": 10200
    },
    {
      "epoch": 3.6525979783649585,
      "grad_norm": 0.00293189799413085,
      "learning_rate": 6.34764100744945e-05,
      "loss": 0.0029,
      "step": 10300
    },
    {
      "epoch": 3.6880652597978365,
      "grad_norm": 0.009499732404947281,
      "learning_rate": 6.31216743526073e-05,
      "loss": 0.003,
      "step": 10400
    },
    {
      "epoch": 3.7235325412307145,
      "grad_norm": 0.0033094706013798714,
      "learning_rate": 6.276693863072012e-05,
      "loss": 0.0029,
      "step": 10500
    },
    {
      "epoch": 3.7235325412307145,
      "eval_loss": 0.0031701617408543825,
      "eval_runtime": 32.1283,
      "eval_samples_per_second": 37.973,
      "eval_steps_per_second": 9.493,
      "step": 10500
    },
    {
      "epoch": 3.7589998226635926,
      "grad_norm": 0.013509562239050865,
      "learning_rate": 6.241220290883292e-05,
      "loss": 0.0031,
      "step": 10600
    },
    {
      "epoch": 3.794467104096471,
      "grad_norm": 0.0073362612165510654,
      "learning_rate": 6.205746718694572e-05,
      "loss": 0.0029,
      "step": 10700
    },
    {
      "epoch": 3.829934385529349,
      "grad_norm": 0.00529636163264513,
      "learning_rate": 6.170273146505854e-05,
      "loss": 0.003,
      "step": 10800
    },
    {
      "epoch": 3.865401666962227,
      "grad_norm": 0.005994605831801891,
      "learning_rate": 6.134799574317134e-05,
      "loss": 0.003,
      "step": 10900
    },
    {
      "epoch": 3.9008689483951056,
      "grad_norm": 0.0031013446860015392,
      "learning_rate": 6.099326002128415e-05,
      "loss": 0.0031,
      "step": 11000
    },
    {
      "epoch": 3.9008689483951056,
      "eval_loss": 0.0031519741751253605,
      "eval_runtime": 32.5011,
      "eval_samples_per_second": 37.537,
      "eval_steps_per_second": 9.384,
      "step": 11000
    },
    {
      "epoch": 3.9363362298279836,
      "grad_norm": 0.010546472854912281,
      "learning_rate": 6.0638524299396946e-05,
      "loss": 0.003,
      "step": 11100
    },
    {
      "epoch": 3.9718035112608616,
      "grad_norm": 0.003979855682700872,
      "learning_rate": 6.028378857750976e-05,
      "loss": 0.003,
      "step": 11200
    },
    {
      "epoch": 4.007093456286576,
      "grad_norm": 0.004077618476003408,
      "learning_rate": 5.992905285562257e-05,
      "loss": 0.003,
      "step": 11300
    },
    {
      "epoch": 4.0425607377194535,
      "grad_norm": 0.0031294790096580982,
      "learning_rate": 5.957431713373537e-05,
      "loss": 0.0029,
      "step": 11400
    },
    {
      "epoch": 4.078028019152332,
      "grad_norm": 0.01430596224963665,
      "learning_rate": 5.921958141184818e-05,
      "loss": 0.003,
      "step": 11500
    },
    {
      "epoch": 4.078028019152332,
      "eval_loss": 0.003140737535431981,
      "eval_runtime": 32.036,
      "eval_samples_per_second": 38.082,
      "eval_steps_per_second": 9.521,
      "step": 11500
    },
    {
      "epoch": 4.11349530058521,
      "grad_norm": 0.002670664107427001,
      "learning_rate": 5.8864845689960976e-05,
      "loss": 0.003,
      "step": 11600
    },
    {
      "epoch": 4.148962582018088,
      "grad_norm": 0.006672894116491079,
      "learning_rate": 5.851010996807379e-05,
      "loss": 0.0031,
      "step": 11700
    },
    {
      "epoch": 4.1844298634509665,
      "grad_norm": 0.004225137177854776,
      "learning_rate": 5.815537424618659e-05,
      "loss": 0.0029,
      "step": 11800
    },
    {
      "epoch": 4.219897144883845,
      "grad_norm": 0.0021301545202732086,
      "learning_rate": 5.78006385242994e-05,
      "loss": 0.0029,
      "step": 11900
    },
    {
      "epoch": 4.2553644263167225,
      "grad_norm": 0.01008719950914383,
      "learning_rate": 5.744590280241221e-05,
      "loss": 0.0029,
      "step": 12000
    },
    {
      "epoch": 4.2553644263167225,
      "eval_loss": 0.0031357586849480867,
      "eval_runtime": 32.2656,
      "eval_samples_per_second": 37.811,
      "eval_steps_per_second": 9.453,
      "step": 12000
    },
    {
      "epoch": 4.290831707749601,
      "grad_norm": 0.007318869233131409,
      "learning_rate": 5.709116708052501e-05,
      "loss": 0.003,
      "step": 12100
    },
    {
      "epoch": 4.3262989891824795,
      "grad_norm": 0.0025576618500053883,
      "learning_rate": 5.673643135863782e-05,
      "loss": 0.003,
      "step": 12200
    },
    {
      "epoch": 4.361766270615357,
      "grad_norm": 0.008131696842610836,
      "learning_rate": 5.638169563675062e-05,
      "loss": 0.0031,
      "step": 12300
    },
    {
      "epoch": 4.3972335520482355,
      "grad_norm": 0.0066711571998894215,
      "learning_rate": 5.602695991486343e-05,
      "loss": 0.003,
      "step": 12400
    },
    {
      "epoch": 4.432700833481114,
      "grad_norm": 0.0046411072835326195,
      "learning_rate": 5.567222419297623e-05,
      "loss": 0.003,
      "step": 12500
    },
    {
      "epoch": 4.432700833481114,
      "eval_loss": 0.003130605211481452,
      "eval_runtime": 32.1712,
      "eval_samples_per_second": 37.922,
      "eval_steps_per_second": 9.481,
      "step": 12500
    },
    {
      "epoch": 4.468168114913992,
      "grad_norm": 0.00419602869078517,
      "learning_rate": 5.531748847108904e-05,
      "loss": 0.003,
      "step": 12600
    },
    {
      "epoch": 4.50363539634687,
      "grad_norm": 0.006784787401556969,
      "learning_rate": 5.496275274920185e-05,
      "loss": 0.0029,
      "step": 12700
    },
    {
      "epoch": 4.5391026777797485,
      "grad_norm": 0.008127707056701183,
      "learning_rate": 5.4608017027314654e-05,
      "loss": 0.0031,
      "step": 12800
    },
    {
      "epoch": 4.574569959212626,
      "grad_norm": 0.011307444423437119,
      "learning_rate": 5.425328130542746e-05,
      "loss": 0.0029,
      "step": 12900
    },
    {
      "epoch": 4.610037240645505,
      "grad_norm": 0.0036534613464027643,
      "learning_rate": 5.389854558354026e-05,
      "loss": 0.003,
      "step": 13000
    },
    {
      "epoch": 4.610037240645505,
      "eval_loss": 0.0031162449158728123,
      "eval_runtime": 31.8735,
      "eval_samples_per_second": 38.276,
      "eval_steps_per_second": 9.569,
      "step": 13000
    },
    {
      "epoch": 4.645504522078383,
      "grad_norm": 0.0031594345346093178,
      "learning_rate": 5.354380986165307e-05,
      "loss": 0.003,
      "step": 13100
    },
    {
      "epoch": 4.680971803511261,
      "grad_norm": 0.003834302304312587,
      "learning_rate": 5.318907413976588e-05,
      "loss": 0.0031,
      "step": 13200
    },
    {
      "epoch": 4.716439084944139,
      "grad_norm": 0.005566726438701153,
      "learning_rate": 5.2834338417878684e-05,
      "loss": 0.0029,
      "step": 13300
    },
    {
      "epoch": 4.751906366377018,
      "grad_norm": 0.00449146656319499,
      "learning_rate": 5.247960269599149e-05,
      "loss": 0.003,
      "step": 13400
    },
    {
      "epoch": 4.787373647809895,
      "grad_norm": 0.00879604835063219,
      "learning_rate": 5.2124866974104295e-05,
      "loss": 0.003,
      "step": 13500
    },
    {
      "epoch": 4.787373647809895,
      "eval_loss": 0.0031165252439677715,
      "eval_runtime": 32.1918,
      "eval_samples_per_second": 37.898,
      "eval_steps_per_second": 9.474,
      "step": 13500
    },
    {
      "epoch": 4.822840929242774,
      "grad_norm": 0.0075650266371667385,
      "learning_rate": 5.17701312522171e-05,
      "loss": 0.003,
      "step": 13600
    },
    {
      "epoch": 4.858308210675652,
      "grad_norm": 0.0030745903495699167,
      "learning_rate": 5.14153955303299e-05,
      "loss": 0.0029,
      "step": 13700
    },
    {
      "epoch": 4.89377549210853,
      "grad_norm": 0.00618739565834403,
      "learning_rate": 5.1060659808442714e-05,
      "loss": 0.003,
      "step": 13800
    },
    {
      "epoch": 4.929242773541408,
      "grad_norm": 0.002928272122517228,
      "learning_rate": 5.070592408655552e-05,
      "loss": 0.0029,
      "step": 13900
    },
    {
      "epoch": 4.964710054974287,
      "grad_norm": 0.0019683653954416513,
      "learning_rate": 5.0351188364668325e-05,
      "loss": 0.003,
      "step": 14000
    },
    {
      "epoch": 4.964710054974287,
      "eval_loss": 0.0031074676662683487,
      "eval_runtime": 31.9479,
      "eval_samples_per_second": 38.187,
      "eval_steps_per_second": 9.547,
      "step": 14000
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0066831368021667,
      "learning_rate": 4.9996452642781134e-05,
      "loss": 0.003,
      "step": 14100
    },
    {
      "epoch": 5.0354672814328785,
      "grad_norm": 0.006774862762540579,
      "learning_rate": 4.9641716920893935e-05,
      "loss": 0.0029,
      "step": 14200
    },
    {
      "epoch": 5.070934562865756,
      "grad_norm": 0.015356425195932388,
      "learning_rate": 4.9286981199006744e-05,
      "loss": 0.0029,
      "step": 14300
    },
    {
      "epoch": 5.1064018442986345,
      "grad_norm": 0.003490688046440482,
      "learning_rate": 4.8932245477119546e-05,
      "loss": 0.0029,
      "step": 14400
    },
    {
      "epoch": 5.141869125731513,
      "grad_norm": 0.002023665001615882,
      "learning_rate": 4.8577509755232355e-05,
      "loss": 0.0031,
      "step": 14500
    },
    {
      "epoch": 5.141869125731513,
      "eval_loss": 0.0030984377954155207,
      "eval_runtime": 32.3021,
      "eval_samples_per_second": 37.768,
      "eval_steps_per_second": 9.442,
      "step": 14500
    },
    {
      "epoch": 5.177336407164391,
      "grad_norm": 0.0050300718285143375,
      "learning_rate": 4.822277403334516e-05,
      "loss": 0.0029,
      "step": 14600
    },
    {
      "epoch": 5.212803688597269,
      "grad_norm": 0.0048910207115113735,
      "learning_rate": 4.7868038311457966e-05,
      "loss": 0.003,
      "step": 14700
    },
    {
      "epoch": 5.2482709700301475,
      "grad_norm": 0.007287527900189161,
      "learning_rate": 4.7513302589570774e-05,
      "loss": 0.003,
      "step": 14800
    },
    {
      "epoch": 5.283738251463025,
      "grad_norm": 0.007586949970573187,
      "learning_rate": 4.7158566867683576e-05,
      "loss": 0.003,
      "step": 14900
    },
    {
      "epoch": 5.319205532895904,
      "grad_norm": 0.007628091145306826,
      "learning_rate": 4.6803831145796385e-05,
      "loss": 0.003,
      "step": 15000
    },
    {
      "epoch": 5.319205532895904,
      "eval_loss": 0.003093455219641328,
      "eval_runtime": 32.0816,
      "eval_samples_per_second": 38.028,
      "eval_steps_per_second": 9.507,
      "step": 15000
    },
    {
      "epoch": 5.354672814328782,
      "grad_norm": 0.007551419548690319,
      "learning_rate": 4.644909542390919e-05,
      "loss": 0.003,
      "step": 15100
    },
    {
      "epoch": 5.39014009576166,
      "grad_norm": 0.007573275361210108,
      "learning_rate": 4.6094359702021996e-05,
      "loss": 0.003,
      "step": 15200
    },
    {
      "epoch": 5.425607377194538,
      "grad_norm": 0.00534901674836874,
      "learning_rate": 4.57396239801348e-05,
      "loss": 0.003,
      "step": 15300
    },
    {
      "epoch": 5.461074658627417,
      "grad_norm": 0.006298459600657225,
      "learning_rate": 4.5384888258247607e-05,
      "loss": 0.0029,
      "step": 15400
    },
    {
      "epoch": 5.496541940060294,
      "grad_norm": 0.0067207664251327515,
      "learning_rate": 4.5030152536360415e-05,
      "loss": 0.0029,
      "step": 15500
    },
    {
      "epoch": 5.496541940060294,
      "eval_loss": 0.0030906694009900093,
      "eval_runtime": 31.9336,
      "eval_samples_per_second": 38.204,
      "eval_steps_per_second": 9.551,
      "step": 15500
    },
    {
      "epoch": 5.532009221493173,
      "grad_norm": 0.011270662769675255,
      "learning_rate": 4.467541681447322e-05,
      "loss": 0.003,
      "step": 15600
    },
    {
      "epoch": 5.56747650292605,
      "grad_norm": 0.006516211666166782,
      "learning_rate": 4.4320681092586026e-05,
      "loss": 0.003,
      "step": 15700
    },
    {
      "epoch": 5.602943784358929,
      "grad_norm": 0.00851553212851286,
      "learning_rate": 4.396594537069883e-05,
      "loss": 0.003,
      "step": 15800
    },
    {
      "epoch": 5.638411065791807,
      "grad_norm": 0.0030820921529084444,
      "learning_rate": 4.361120964881164e-05,
      "loss": 0.0029,
      "step": 15900
    },
    {
      "epoch": 5.673878347224685,
      "grad_norm": 0.002966090338304639,
      "learning_rate": 4.3256473926924445e-05,
      "loss": 0.0028,
      "step": 16000
    },
    {
      "epoch": 5.673878347224685,
      "eval_loss": 0.0030757582280784845,
      "eval_runtime": 32.1678,
      "eval_samples_per_second": 37.926,
      "eval_steps_per_second": 9.482,
      "step": 16000
    },
    {
      "epoch": 5.709345628657563,
      "grad_norm": 0.0034582051448524,
      "learning_rate": 4.290173820503725e-05,
      "loss": 0.0029,
      "step": 16100
    },
    {
      "epoch": 5.744812910090442,
      "grad_norm": 0.005606039892882109,
      "learning_rate": 4.2547002483150056e-05,
      "loss": 0.0029,
      "step": 16200
    },
    {
      "epoch": 5.780280191523319,
      "grad_norm": 0.0071020228788256645,
      "learning_rate": 4.2195814118481734e-05,
      "loss": 0.003,
      "step": 16300
    },
    {
      "epoch": 5.815747472956198,
      "grad_norm": 0.005011075176298618,
      "learning_rate": 4.184107839659454e-05,
      "loss": 0.0029,
      "step": 16400
    },
    {
      "epoch": 5.851214754389076,
      "grad_norm": 0.011285116896033287,
      "learning_rate": 4.1486342674707344e-05,
      "loss": 0.003,
      "step": 16500
    },
    {
      "epoch": 5.851214754389076,
      "eval_loss": 0.0030829221941530704,
      "eval_runtime": 32.082,
      "eval_samples_per_second": 38.028,
      "eval_steps_per_second": 9.507,
      "step": 16500
    },
    {
      "epoch": 5.886682035821954,
      "grad_norm": 0.003207847708836198,
      "learning_rate": 4.113160695282015e-05,
      "loss": 0.003,
      "step": 16600
    },
    {
      "epoch": 5.922149317254832,
      "grad_norm": 0.0015196362510323524,
      "learning_rate": 4.0776871230932955e-05,
      "loss": 0.003,
      "step": 16700
    },
    {
      "epoch": 5.957616598687711,
      "grad_norm": 0.008445643819868565,
      "learning_rate": 4.0422135509045764e-05,
      "loss": 0.0029,
      "step": 16800
    },
    {
      "epoch": 5.993083880120588,
      "grad_norm": 0.003999689593911171,
      "learning_rate": 4.0067399787158566e-05,
      "loss": 0.003,
      "step": 16900
    },
    {
      "epoch": 6.028373825146303,
      "grad_norm": 0.00873100571334362,
      "learning_rate": 3.9712664065271375e-05,
      "loss": 0.0028,
      "step": 17000
    },
    {
      "epoch": 6.028373825146303,
      "eval_loss": 0.0030671104323118925,
      "eval_runtime": 31.9301,
      "eval_samples_per_second": 38.208,
      "eval_steps_per_second": 9.552,
      "step": 17000
    },
    {
      "epoch": 6.063841106579181,
      "grad_norm": 0.004534776322543621,
      "learning_rate": 3.935792834338418e-05,
      "loss": 0.003,
      "step": 17100
    },
    {
      "epoch": 6.099308388012059,
      "grad_norm": 0.0027793836779892445,
      "learning_rate": 3.9003192621496985e-05,
      "loss": 0.0029,
      "step": 17200
    },
    {
      "epoch": 6.134775669444937,
      "grad_norm": 0.005719552282243967,
      "learning_rate": 3.8648456899609794e-05,
      "loss": 0.0028,
      "step": 17300
    },
    {
      "epoch": 6.170242950877816,
      "grad_norm": 0.006540128029882908,
      "learning_rate": 3.8293721177722596e-05,
      "loss": 0.0029,
      "step": 17400
    },
    {
      "epoch": 6.205710232310693,
      "grad_norm": 0.004314285237342119,
      "learning_rate": 3.7938985455835405e-05,
      "loss": 0.0029,
      "step": 17500
    },
    {
      "epoch": 6.205710232310693,
      "eval_loss": 0.003065386088564992,
      "eval_runtime": 32.18,
      "eval_samples_per_second": 37.912,
      "eval_steps_per_second": 9.478,
      "step": 17500
    },
    {
      "epoch": 6.241177513743572,
      "grad_norm": 0.0022307352628558874,
      "learning_rate": 3.7584249733948214e-05,
      "loss": 0.003,
      "step": 17600
    },
    {
      "epoch": 6.27664479517645,
      "grad_norm": 0.003677965374663472,
      "learning_rate": 3.7229514012061015e-05,
      "loss": 0.003,
      "step": 17700
    },
    {
      "epoch": 6.312112076609328,
      "grad_norm": 0.006451938301324844,
      "learning_rate": 3.6874778290173824e-05,
      "loss": 0.0029,
      "step": 17800
    },
    {
      "epoch": 6.347579358042206,
      "grad_norm": 0.006010925397276878,
      "learning_rate": 3.6520042568286626e-05,
      "loss": 0.0029,
      "step": 17900
    },
    {
      "epoch": 6.383046639475085,
      "grad_norm": 0.00597646739333868,
      "learning_rate": 3.6165306846399435e-05,
      "loss": 0.0029,
      "step": 18000
    },
    {
      "epoch": 6.383046639475085,
      "eval_loss": 0.003056759014725685,
      "eval_runtime": 32.3442,
      "eval_samples_per_second": 37.719,
      "eval_steps_per_second": 9.43,
      "step": 18000
    },
    {
      "epoch": 6.418513920907962,
      "grad_norm": 0.0059533920139074326,
      "learning_rate": 3.581057112451224e-05,
      "loss": 0.003,
      "step": 18100
    },
    {
      "epoch": 6.453981202340841,
      "grad_norm": 0.003296410897746682,
      "learning_rate": 3.5455835402625046e-05,
      "loss": 0.0029,
      "step": 18200
    },
    {
      "epoch": 6.489448483773719,
      "grad_norm": 0.010541985742747784,
      "learning_rate": 3.5101099680737854e-05,
      "loss": 0.0029,
      "step": 18300
    },
    {
      "epoch": 6.524915765206597,
      "grad_norm": 0.003899678587913513,
      "learning_rate": 3.4749911316069525e-05,
      "loss": 0.0029,
      "step": 18400
    },
    {
      "epoch": 6.560383046639475,
      "grad_norm": 0.004743083380162716,
      "learning_rate": 3.439517559418234e-05,
      "loss": 0.0029,
      "step": 18500
    },
    {
      "epoch": 6.560383046639475,
      "eval_loss": 0.0030571913812309504,
      "eval_runtime": 32.144,
      "eval_samples_per_second": 37.954,
      "eval_steps_per_second": 9.489,
      "step": 18500
    },
    {
      "epoch": 6.595850328072354,
      "grad_norm": 0.004622352309525013,
      "learning_rate": 3.404043987229514e-05,
      "loss": 0.003,
      "step": 18600
    },
    {
      "epoch": 6.631317609505231,
      "grad_norm": 0.002643088810145855,
      "learning_rate": 3.368570415040795e-05,
      "loss": 0.0029,
      "step": 18700
    },
    {
      "epoch": 6.66678489093811,
      "grad_norm": 0.00803092960268259,
      "learning_rate": 3.3330968428520753e-05,
      "loss": 0.0029,
      "step": 18800
    },
    {
      "epoch": 6.702252172370988,
      "grad_norm": 0.007017576601356268,
      "learning_rate": 3.2976232706633555e-05,
      "loss": 0.0029,
      "step": 18900
    },
    {
      "epoch": 6.737719453803866,
      "grad_norm": 0.0039962464943528175,
      "learning_rate": 3.2621496984746364e-05,
      "loss": 0.003,
      "step": 19000
    },
    {
      "epoch": 6.737719453803866,
      "eval_loss": 0.003051611129194498,
      "eval_runtime": 32.1486,
      "eval_samples_per_second": 37.949,
      "eval_steps_per_second": 9.487,
      "step": 19000
    },
    {
      "epoch": 6.773186735236744,
      "grad_norm": 0.006812006700783968,
      "learning_rate": 3.226676126285917e-05,
      "loss": 0.0029,
      "step": 19100
    },
    {
      "epoch": 6.808654016669622,
      "grad_norm": 0.0036347643472254276,
      "learning_rate": 3.191202554097198e-05,
      "loss": 0.003,
      "step": 19200
    },
    {
      "epoch": 6.8441212981025,
      "grad_norm": 0.0031169818248599768,
      "learning_rate": 3.1557289819084784e-05,
      "loss": 0.0029,
      "step": 19300
    },
    {
      "epoch": 6.879588579535379,
      "grad_norm": 0.005312979221343994,
      "learning_rate": 3.120255409719759e-05,
      "loss": 0.0029,
      "step": 19400
    },
    {
      "epoch": 6.915055860968256,
      "grad_norm": 0.007033288013190031,
      "learning_rate": 3.0847818375310394e-05,
      "loss": 0.0029,
      "step": 19500
    },
    {
      "epoch": 6.915055860968256,
      "eval_loss": 0.0030532372184097767,
      "eval_runtime": 31.7714,
      "eval_samples_per_second": 38.399,
      "eval_steps_per_second": 9.6,
      "step": 19500
    },
    {
      "epoch": 6.950523142401135,
      "grad_norm": 0.004551850259304047,
      "learning_rate": 3.04930826534232e-05,
      "loss": 0.0029,
      "step": 19600
    },
    {
      "epoch": 6.985990423834013,
      "grad_norm": 0.0038954352494329214,
      "learning_rate": 3.0138346931536005e-05,
      "loss": 0.0029,
      "step": 19700
    },
    {
      "epoch": 7.021280368859727,
      "grad_norm": 0.009294294752180576,
      "learning_rate": 2.9783611209648814e-05,
      "loss": 0.0029,
      "step": 19800
    },
    {
      "epoch": 7.056747650292605,
      "grad_norm": 0.003574670758098364,
      "learning_rate": 2.942887548776162e-05,
      "loss": 0.0028,
      "step": 19900
    },
    {
      "epoch": 7.092214931725484,
      "grad_norm": 0.0032269377261400223,
      "learning_rate": 2.9074139765874424e-05,
      "loss": 0.003,
      "step": 20000
    },
    {
      "epoch": 7.092214931725484,
      "eval_loss": 0.003043679054826498,
      "eval_runtime": 31.9519,
      "eval_samples_per_second": 38.182,
      "eval_steps_per_second": 9.546,
      "step": 20000
    },
    {
      "epoch": 7.127682213158361,
      "grad_norm": 0.0038698751013725996,
      "learning_rate": 2.871940404398723e-05,
      "loss": 0.0029,
      "step": 20100
    },
    {
      "epoch": 7.16314949459124,
      "grad_norm": 0.0030861287377774715,
      "learning_rate": 2.8364668322100035e-05,
      "loss": 0.0029,
      "step": 20200
    },
    {
      "epoch": 7.198616776024117,
      "grad_norm": 0.005751836113631725,
      "learning_rate": 2.800993260021284e-05,
      "loss": 0.003,
      "step": 20300
    },
    {
      "epoch": 7.234084057456996,
      "grad_norm": 0.012011540122330189,
      "learning_rate": 2.765874423554452e-05,
      "loss": 0.0029,
      "step": 20400
    },
    {
      "epoch": 7.269551338889874,
      "grad_norm": 0.0031723566353321075,
      "learning_rate": 2.7304008513657327e-05,
      "loss": 0.0029,
      "step": 20500
    },
    {
      "epoch": 7.269551338889874,
      "eval_loss": 0.00304054981097579,
      "eval_runtime": 32.1673,
      "eval_samples_per_second": 37.927,
      "eval_steps_per_second": 9.482,
      "step": 20500
    },
    {
      "epoch": 7.305018620322752,
      "grad_norm": 0.002596542239189148,
      "learning_rate": 2.694927279177013e-05,
      "loss": 0.0029,
      "step": 20600
    },
    {
      "epoch": 7.34048590175563,
      "grad_norm": 0.00777166523039341,
      "learning_rate": 2.659453706988294e-05,
      "loss": 0.0029,
      "step": 20700
    },
    {
      "epoch": 7.375953183188509,
      "grad_norm": 0.0066011701710522175,
      "learning_rate": 2.6239801347995746e-05,
      "loss": 0.0029,
      "step": 20800
    },
    {
      "epoch": 7.411420464621386,
      "grad_norm": 0.004823398310691118,
      "learning_rate": 2.588506562610855e-05,
      "loss": 0.0029,
      "step": 20900
    },
    {
      "epoch": 7.446887746054265,
      "grad_norm": 0.0025528164114803076,
      "learning_rate": 2.5530329904221357e-05,
      "loss": 0.0028,
      "step": 21000
    },
    {
      "epoch": 7.446887746054265,
      "eval_loss": 0.0030354266054928303,
      "eval_runtime": 31.6261,
      "eval_samples_per_second": 38.576,
      "eval_steps_per_second": 9.644,
      "step": 21000
    },
    {
      "epoch": 7.482355027487143,
      "grad_norm": 0.0028371417429298162,
      "learning_rate": 2.5175594182334162e-05,
      "loss": 0.0029,
      "step": 21100
    },
    {
      "epoch": 7.517822308920021,
      "grad_norm": 0.0029655962716788054,
      "learning_rate": 2.4820858460446968e-05,
      "loss": 0.0029,
      "step": 21200
    },
    {
      "epoch": 7.553289590352899,
      "grad_norm": 0.00372823397628963,
      "learning_rate": 2.4466122738559773e-05,
      "loss": 0.0029,
      "step": 21300
    },
    {
      "epoch": 7.588756871785778,
      "grad_norm": 0.005644060205668211,
      "learning_rate": 2.411138701667258e-05,
      "loss": 0.0028,
      "step": 21400
    },
    {
      "epoch": 7.624224153218655,
      "grad_norm": 0.0034274659119546413,
      "learning_rate": 2.3756651294785387e-05,
      "loss": 0.0029,
      "step": 21500
    },
    {
      "epoch": 7.624224153218655,
      "eval_loss": 0.003032037988305092,
      "eval_runtime": 32.1843,
      "eval_samples_per_second": 37.907,
      "eval_steps_per_second": 9.477,
      "step": 21500
    },
    {
      "epoch": 7.659691434651534,
      "grad_norm": 0.0026778404135257006,
      "learning_rate": 2.3401915572898193e-05,
      "loss": 0.0028,
      "step": 21600
    },
    {
      "epoch": 7.695158716084412,
      "grad_norm": 0.0028892764821648598,
      "learning_rate": 2.3047179851010998e-05,
      "loss": 0.0029,
      "step": 21700
    },
    {
      "epoch": 7.73062599751729,
      "grad_norm": 0.006488202139735222,
      "learning_rate": 2.2692444129123803e-05,
      "loss": 0.0028,
      "step": 21800
    },
    {
      "epoch": 7.766093278950168,
      "grad_norm": 0.0037472345866262913,
      "learning_rate": 2.233770840723661e-05,
      "loss": 0.0028,
      "step": 21900
    },
    {
      "epoch": 7.801560560383047,
      "grad_norm": 0.0059516699984669685,
      "learning_rate": 2.1982972685349414e-05,
      "loss": 0.0028,
      "step": 22000
    },
    {
      "epoch": 7.801560560383047,
      "eval_loss": 0.0030378622468560934,
      "eval_runtime": 32.098,
      "eval_samples_per_second": 38.009,
      "eval_steps_per_second": 9.502,
      "step": 22000
    },
    {
      "epoch": 7.8370278418159245,
      "grad_norm": 0.0036215870641171932,
      "learning_rate": 2.1628236963462223e-05,
      "loss": 0.0029,
      "step": 22100
    },
    {
      "epoch": 7.872495123248803,
      "grad_norm": 0.002205824013799429,
      "learning_rate": 2.1273501241575028e-05,
      "loss": 0.0028,
      "step": 22200
    },
    {
      "epoch": 7.907962404681681,
      "grad_norm": 0.003029830753803253,
      "learning_rate": 2.0918765519687833e-05,
      "loss": 0.0029,
      "step": 22300
    },
    {
      "epoch": 7.943429686114559,
      "grad_norm": 0.0030944058671593666,
      "learning_rate": 2.0564029797800642e-05,
      "loss": 0.0029,
      "step": 22400
    },
    {
      "epoch": 7.9788969675474375,
      "grad_norm": 0.0030245298985391855,
      "learning_rate": 2.0209294075913444e-05,
      "loss": 0.0029,
      "step": 22500
    },
    {
      "epoch": 7.9788969675474375,
      "eval_loss": 0.0030302281957119703,
      "eval_runtime": 31.8882,
      "eval_samples_per_second": 38.259,
      "eval_steps_per_second": 9.565,
      "step": 22500
    },
    {
      "epoch": 8.014186912573152,
      "grad_norm": 0.003578932723030448,
      "learning_rate": 1.9858105711245122e-05,
      "loss": 0.0029,
      "step": 22600
    },
    {
      "epoch": 8.04965419400603,
      "grad_norm": 0.0021379520185291767,
      "learning_rate": 1.9503369989357927e-05,
      "loss": 0.0028,
      "step": 22700
    },
    {
      "epoch": 8.085121475438907,
      "grad_norm": 0.014811474829912186,
      "learning_rate": 1.9148634267470736e-05,
      "loss": 0.0029,
      "step": 22800
    },
    {
      "epoch": 8.120588756871786,
      "grad_norm": 0.003091868245974183,
      "learning_rate": 1.879389854558354e-05,
      "loss": 0.0029,
      "step": 22900
    },
    {
      "epoch": 8.156056038304664,
      "grad_norm": 0.004937867168337107,
      "learning_rate": 1.8439162823696347e-05,
      "loss": 0.0028,
      "step": 23000
    },
    {
      "epoch": 8.156056038304664,
      "eval_loss": 0.003025445155799389,
      "eval_runtime": 31.8828,
      "eval_samples_per_second": 38.265,
      "eval_steps_per_second": 9.566,
      "step": 23000
    },
    {
      "epoch": 8.191523319737541,
      "grad_norm": 0.0034409742802381516,
      "learning_rate": 1.8084427101809155e-05,
      "loss": 0.0029,
      "step": 23100
    },
    {
      "epoch": 8.22699060117042,
      "grad_norm": 0.005390573292970657,
      "learning_rate": 1.7729691379921957e-05,
      "loss": 0.0028,
      "step": 23200
    },
    {
      "epoch": 8.262457882603298,
      "grad_norm": 0.003501061350107193,
      "learning_rate": 1.7374955658034763e-05,
      "loss": 0.0028,
      "step": 23300
    },
    {
      "epoch": 8.297925164036176,
      "grad_norm": 0.007568489294499159,
      "learning_rate": 1.702021993614757e-05,
      "loss": 0.003,
      "step": 23400
    },
    {
      "epoch": 8.333392445469055,
      "grad_norm": 0.004723185207694769,
      "learning_rate": 1.6665484214260377e-05,
      "loss": 0.0028,
      "step": 23500
    },
    {
      "epoch": 8.333392445469055,
      "eval_loss": 0.003022300312295556,
      "eval_runtime": 31.701,
      "eval_samples_per_second": 38.485,
      "eval_steps_per_second": 9.621,
      "step": 23500
    },
    {
      "epoch": 8.368859726901933,
      "grad_norm": 0.005630730651319027,
      "learning_rate": 1.6310748492373182e-05,
      "loss": 0.003,
      "step": 23600
    },
    {
      "epoch": 8.40432700833481,
      "grad_norm": 0.00615307129919529,
      "learning_rate": 1.595601277048599e-05,
      "loss": 0.0029,
      "step": 23700
    },
    {
      "epoch": 8.43979428976769,
      "grad_norm": 0.0036120640579611063,
      "learning_rate": 1.5601277048598796e-05,
      "loss": 0.0029,
      "step": 23800
    },
    {
      "epoch": 8.475261571200567,
      "grad_norm": 0.003790629096329212,
      "learning_rate": 1.52465413267116e-05,
      "loss": 0.0029,
      "step": 23900
    },
    {
      "epoch": 8.510728852633445,
      "grad_norm": 0.00364501029253006,
      "learning_rate": 1.4891805604824407e-05,
      "loss": 0.0029,
      "step": 24000
    },
    {
      "epoch": 8.510728852633445,
      "eval_loss": 0.0030218781903386116,
      "eval_runtime": 32.0756,
      "eval_samples_per_second": 38.035,
      "eval_steps_per_second": 9.509,
      "step": 24000
    },
    {
      "epoch": 8.546196134066324,
      "grad_norm": 0.006436734460294247,
      "learning_rate": 1.4537069882937212e-05,
      "loss": 0.0029,
      "step": 24100
    },
    {
      "epoch": 8.581663415499202,
      "grad_norm": 0.0012519537704065442,
      "learning_rate": 1.4182334161050018e-05,
      "loss": 0.0028,
      "step": 24200
    },
    {
      "epoch": 8.61713069693208,
      "grad_norm": 0.0029935860075056553,
      "learning_rate": 1.3827598439162826e-05,
      "loss": 0.003,
      "step": 24300
    },
    {
      "epoch": 8.652597978364959,
      "grad_norm": 0.006750847678631544,
      "learning_rate": 1.347286271727563e-05,
      "loss": 0.0028,
      "step": 24400
    },
    {
      "epoch": 8.688065259797837,
      "grad_norm": 0.006858058273792267,
      "learning_rate": 1.3118126995388435e-05,
      "loss": 0.0029,
      "step": 24500
    },
    {
      "epoch": 8.688065259797837,
      "eval_loss": 0.003017861396074295,
      "eval_runtime": 31.8327,
      "eval_samples_per_second": 38.325,
      "eval_steps_per_second": 9.581,
      "step": 24500
    },
    {
      "epoch": 8.723532541230714,
      "grad_norm": 0.005915173329412937,
      "learning_rate": 1.2763391273501244e-05,
      "loss": 0.0029,
      "step": 24600
    },
    {
      "epoch": 8.758999822663593,
      "grad_norm": 0.007881702855229378,
      "learning_rate": 1.2408655551614048e-05,
      "loss": 0.0029,
      "step": 24700
    },
    {
      "epoch": 8.794467104096471,
      "grad_norm": 0.0027147929649800062,
      "learning_rate": 1.2053919829726853e-05,
      "loss": 0.0029,
      "step": 24800
    },
    {
      "epoch": 8.829934385529349,
      "grad_norm": 0.00288560357876122,
      "learning_rate": 1.169918410783966e-05,
      "loss": 0.0028,
      "step": 24900
    },
    {
      "epoch": 8.865401666962228,
      "grad_norm": 0.0031873146072030067,
      "learning_rate": 1.1344448385952467e-05,
      "loss": 0.0028,
      "step": 25000
    },
    {
      "epoch": 8.865401666962228,
      "eval_loss": 0.0030156318098306656,
      "eval_runtime": 32.1578,
      "eval_samples_per_second": 37.938,
      "eval_steps_per_second": 9.484,
      "step": 25000
    },
    {
      "epoch": 8.900868948395106,
      "grad_norm": 0.005309358239173889,
      "learning_rate": 1.0989712664065271e-05,
      "loss": 0.0028,
      "step": 25100
    },
    {
      "epoch": 8.936336229827983,
      "grad_norm": 0.0022275771480053663,
      "learning_rate": 1.0634976942178078e-05,
      "loss": 0.0028,
      "step": 25200
    },
    {
      "epoch": 8.971803511260863,
      "grad_norm": 0.0019402009202167392,
      "learning_rate": 1.0280241220290885e-05,
      "loss": 0.0029,
      "step": 25300
    },
    {
      "epoch": 9.007093456286576,
      "grad_norm": 0.0021833772771060467,
      "learning_rate": 9.929052855622561e-06,
      "loss": 0.0029,
      "step": 25400
    },
    {
      "epoch": 9.042560737719453,
      "grad_norm": 0.0029822117649018764,
      "learning_rate": 9.574317133735368e-06,
      "loss": 0.003,
      "step": 25500
    },
    {
      "epoch": 9.042560737719453,
      "eval_loss": 0.003015840658918023,
      "eval_runtime": 31.9032,
      "eval_samples_per_second": 38.241,
      "eval_steps_per_second": 9.56,
      "step": 25500
    },
    {
      "epoch": 9.078028019152333,
      "grad_norm": 0.0064801545813679695,
      "learning_rate": 9.219581411848173e-06,
      "loss": 0.003,
      "step": 25600
    },
    {
      "epoch": 9.11349530058521,
      "grad_norm": 0.009668576531112194,
      "learning_rate": 8.864845689960979e-06,
      "loss": 0.0028,
      "step": 25700
    },
    {
      "epoch": 9.148962582018088,
      "grad_norm": 0.0037242129910737276,
      "learning_rate": 8.510109968073786e-06,
      "loss": 0.0028,
      "step": 25800
    },
    {
      "epoch": 9.184429863450967,
      "grad_norm": 0.003022347344085574,
      "learning_rate": 8.155374246186591e-06,
      "loss": 0.0028,
      "step": 25900
    },
    {
      "epoch": 9.219897144883845,
      "grad_norm": 0.0042261043563485146,
      "learning_rate": 7.800638524299398e-06,
      "loss": 0.0028,
      "step": 26000
    },
    {
      "epoch": 9.219897144883845,
      "eval_loss": 0.003013355191797018,
      "eval_runtime": 32.1951,
      "eval_samples_per_second": 37.894,
      "eval_steps_per_second": 9.473,
      "step": 26000
    },
    {
      "epoch": 9.255364426316723,
      "grad_norm": 0.0021405769512057304,
      "learning_rate": 7.4459028024122034e-06,
      "loss": 0.0028,
      "step": 26100
    },
    {
      "epoch": 9.2908317077496,
      "grad_norm": 0.002084410050883889,
      "learning_rate": 7.091167080525009e-06,
      "loss": 0.0029,
      "step": 26200
    },
    {
      "epoch": 9.32629898918248,
      "grad_norm": 0.0020103096030652523,
      "learning_rate": 6.736431358637815e-06,
      "loss": 0.0029,
      "step": 26300
    },
    {
      "epoch": 9.361766270615357,
      "grad_norm": 0.004655936267226934,
      "learning_rate": 6.381695636750622e-06,
      "loss": 0.0028,
      "step": 26400
    },
    {
      "epoch": 9.397233552048235,
      "grad_norm": 0.0026423295494168997,
      "learning_rate": 6.0269599148634266e-06,
      "loss": 0.0029,
      "step": 26500
    },
    {
      "epoch": 9.397233552048235,
      "eval_loss": 0.0030117135029286146,
      "eval_runtime": 32.4667,
      "eval_samples_per_second": 37.577,
      "eval_steps_per_second": 9.394,
      "step": 26500
    },
    {
      "epoch": 9.432700833481114,
      "grad_norm": 0.005294149741530418,
      "learning_rate": 5.672224192976234e-06,
      "loss": 0.0029,
      "step": 26600
    },
    {
      "epoch": 9.468168114913992,
      "grad_norm": 0.004420991986989975,
      "learning_rate": 5.317488471089039e-06,
      "loss": 0.0029,
      "step": 26700
    },
    {
      "epoch": 9.50363539634687,
      "grad_norm": 0.0062520201317965984,
      "learning_rate": 4.962752749201844e-06,
      "loss": 0.0028,
      "step": 26800
    },
    {
      "epoch": 9.539102677779749,
      "grad_norm": 0.004149644635617733,
      "learning_rate": 4.608017027314651e-06,
      "loss": 0.0029,
      "step": 26900
    },
    {
      "epoch": 9.574569959212626,
      "grad_norm": 0.0021027661859989166,
      "learning_rate": 4.253281305427457e-06,
      "loss": 0.0028,
      "step": 27000
    },
    {
      "epoch": 9.574569959212626,
      "eval_loss": 0.0030106855556368828,
      "eval_runtime": 31.8715,
      "eval_samples_per_second": 38.279,
      "eval_steps_per_second": 9.57,
      "step": 27000
    },
    {
      "epoch": 9.610037240645504,
      "grad_norm": 0.003310425439849496,
      "learning_rate": 3.898545583540263e-06,
      "loss": 0.0028,
      "step": 27100
    },
    {
      "epoch": 9.645504522078383,
      "grad_norm": 0.005287267733365297,
      "learning_rate": 3.5438098616530683e-06,
      "loss": 0.0028,
      "step": 27200
    },
    {
      "epoch": 9.68097180351126,
      "grad_norm": 0.005121696274727583,
      "learning_rate": 3.189074139765875e-06,
      "loss": 0.0028,
      "step": 27300
    },
    {
      "epoch": 9.716439084944138,
      "grad_norm": 0.004776631016284227,
      "learning_rate": 2.8343384178786807e-06,
      "loss": 0.0029,
      "step": 27400
    },
    {
      "epoch": 9.751906366377018,
      "grad_norm": 0.0029725306667387486,
      "learning_rate": 2.4796026959914865e-06,
      "loss": 0.0029,
      "step": 27500
    },
    {
      "epoch": 9.751906366377018,
      "eval_loss": 0.0030096860136836767,
      "eval_runtime": 32.2558,
      "eval_samples_per_second": 37.823,
      "eval_steps_per_second": 9.456,
      "step": 27500
    },
    {
      "epoch": 9.787373647809895,
      "grad_norm": 0.002363826846703887,
      "learning_rate": 2.1248669741042922e-06,
      "loss": 0.0029,
      "step": 27600
    },
    {
      "epoch": 9.822840929242773,
      "grad_norm": 0.002581810113042593,
      "learning_rate": 1.7701312522170984e-06,
      "loss": 0.0028,
      "step": 27700
    },
    {
      "epoch": 9.858308210675652,
      "grad_norm": 0.0027882419526576996,
      "learning_rate": 1.4153955303299042e-06,
      "loss": 0.0029,
      "step": 27800
    },
    {
      "epoch": 9.89377549210853,
      "grad_norm": 0.0059376549907028675,
      "learning_rate": 1.0606598084427102e-06,
      "loss": 0.0027,
      "step": 27900
    },
    {
      "epoch": 9.929242773541407,
      "grad_norm": 0.005302311386913061,
      "learning_rate": 7.059240865555161e-07,
      "loss": 0.0028,
      "step": 28000
    },
    {
      "epoch": 9.929242773541407,
      "eval_loss": 0.003009282983839512,
      "eval_runtime": 32.0748,
      "eval_samples_per_second": 38.036,
      "eval_steps_per_second": 9.509,
      "step": 28000
    }
  ],
  "logging_steps": 100,
  "max_steps": 28190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4712542783367485e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
